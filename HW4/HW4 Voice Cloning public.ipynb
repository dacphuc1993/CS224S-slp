{"cells":[{"cell_type":"markdown","metadata":{"id":"7nqvJn5sXouZ"},"source":["# CS224S HW4: Voice Cloning with neural models\n","\n","This part of the homework is worth 40/100 total points for the overall assignment. The goal for this part of the homework is simple -- clone your own voice using some reasonably state of the art neural modeling approaches! You can see the voice cloning framework we are using described [here](https://github.com/CorentinJ/Real-Time-Voice-Cloning). Roughly, there is a neural network which generates a speaker embedding from audio, and a neural TTS system which conditions on this speaker embedding to create an adjusted audio sample for a given text input. \n","\n","Goals for this work:\n","* Record a sample of your own voice and use it as input to a voice cloning system\n","* Try variations of inputs for speaker embeddings and input text to understand how well this voice cloning solution works in practice\n","* Visualize spectograms from real vs synthesized audio examples to compare them\n","\n","**Note:** You will need to make a copy of this Colab notebook in your Google Drive before you can edit it."]},{"cell_type":"markdown","metadata":{"id":"133ELZsy1qAf"},"source":["# Dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i6sCauYLe4jF"},"outputs":[],"source":["!git clone https://github.com/CorentinJ/Real-Time-Voice-Cloning.git\n","!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n","!pip install -r Real-Time-Voice-Cloning/requirements.txt -q\n","!pip install --upgrade matplotlib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U_w8fOs9goPt"},"outputs":[],"source":["# used to play audio files as in HW1\n","import IPython.display as ipd\n","from base64 import b64decode\n","import librosa\n","import librosa.display\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","RECORD = \"\"\"\n","const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n","const b2text = blob => new Promise(resolve => {\n","  const reader = new FileReader()\n","  reader.onloadend = e => resolve(e.srcElement.result)\n","  reader.readAsDataURL(blob)\n","})\n","var record = time => new Promise(async resolve => {\n","  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n","  recorder = new MediaRecorder(stream)\n","  chunks = []\n","  recorder.ondataavailable = e => chunks.push(e.data)\n","  recorder.start()\n","  await sleep(time)\n","  recorder.onstop = async ()=>{\n","    blob = new Blob(chunks)\n","    text = await b2text(blob)\n","    resolve(text)\n","  }\n","  recorder.stop()\n","})\n","\"\"\"\n","\n","def record(sec=5):\n","  try:\n","    from google.colab import output\n","  except ImportError:\n","    print('No possible to import output from google.colab')\n","    return ''\n","  else:\n","    print('Recording')\n","    display(ipd.Javascript(RECORD))\n","    s = output.eval_js('record(%d)' % (sec*1000))\n","    fname = 'recorded_audio.wav'\n","    print('Saving to', fname)\n","    b = b64decode(s.split(',')[1])\n","    with open(fname, 'wb') as f:\n","      f.write(b)\n","    return fname\n","\n","\n","# helper function to plot a mel spectrogram\n","# arguments: (wave array, sampling rate, number of mel bins, max frequency of mel scale)\n","def plot_melspectrogram(wav, sr, annotations=None, n_mels=256, fmax=4096, \n","                        fig=None, ax=None, show_legend=True):\n","    \n","    if ax == None:\n","        fig, ax = plt.subplots(1,1,figsize=(20,5))\n","    M = librosa.feature.melspectrogram(y=wav, sr=sr, n_mels=n_mels, fmax=fmax, n_fft=2048)\n","    M_db = librosa.power_to_db(M, ref=np.max)\n","    img = librosa.display.specshow(M_db, y_axis='mel', x_axis='time', ax=ax, fmax=fmax)\n","    if show_legend:\n","        ax.set(title='Mel spectrogram display')\n","        fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n","        \n","    # iterate over list of text annotations and draw them\n","    if annotations is not None:\n","        for x,y,text in annotations:\n","            ax.annotate(\n","            text,\n","            xy=(x,y), xycoords='data',\n","            xytext=(10, -50), textcoords='offset pixels',\n","            horizontalalignment='right',\n","            color='white',\n","            fontsize=20,\n","            verticalalignment='bottom',\n","            arrowprops=dict(\n","                arrowstyle= '-|>',\n","                 color='white',\n","                 lw=1,\n","                 ls='-')\n","            ) "]},{"cell_type":"markdown","metadata":{"id":"ulx8NWQVYioK"},"source":["# Record and clone **your** voice\n","\n","In this colab, we'll be poking around a [toolkit](https://github.com/CorentinJ/Real-Time-Voice-Cloning) for cloning your own voice. It's important that we only use this tool for good--do **not** record others without their permission.\n","\n","Note: if recording your voice doesn't work, feel free to comment on one of the examples in the `Real-Time-Voice-Cloning/samples` directory.\n"]},{"cell_type":"markdown","metadata":{"id":"ZXxChMt7ndpK"},"source":["## **Task: Record your voice and plot a spectrogram**. (5 points)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qmsP6vzzhACD"},"outputs":[],"source":["record(5)\n","input_path = 'recorded_audio.wav'\n","ipd.Audio(input_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cXs4Rr4U5NBX"},"outputs":[],"source":["input_wav, input_sr = librosa.load(input_path)\n","plot_melspectrogram(input_wav, input_sr)"]},{"cell_type":"markdown","metadata":{"id":"7Ce5pADu0YcI"},"source":["Now use the tool to synthesize the exact same words you said."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kuoamCSnhTzx"},"outputs":[],"source":["# If the downloads fail, try again after a minute or run this commented code.\n","# You can also download the models locally and manually drag them into the \n","# colab file structure\n","# !gdown --folder 1fU6umc5uQAVR2udZdHX-lDgXYzTyqG_j\n","# !mv /content/RTVC\\ models /content/default\n","# !mv default Real-Time-Voice-Cloning/saved_models/default\n","\n","# Use the stop button or Runtime->Interrupt Execution when finished\n","# Please click into the output cell to enter the path when prompted\n","!python Real-Time-Voice-Cloning/demo_cli.py"]},{"cell_type":"markdown","metadata":{"id":"pNwoNr1QoUik"},"source":["## **Task: Run voice conversion and plot some output** (5 points)"]},{"cell_type":"markdown","metadata":{"id":"LPMnQ5H9oqI7"},"source":["Run the voice conversion steps above on your audio sample. This should render an audio file with a TTS system producing the requested output using the requested speaker embedding.\n","\n","Play the audio file and plot a spectrogram."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VIHm62MUjG_k"},"outputs":[],"source":["output_path = 'demo_output_00.wav' # change this as necessary\n","ipd.Audio(output_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Rvxtno1rfS-"},"outputs":[],"source":["    #############################\n","    #### YOUR CODE GOES HERE ####\n","\n","    #############################"]},{"cell_type":"markdown","metadata":{"id":"nnJA_cAOnBle"},"source":["## **Task: Compare spectrograms of original and synthesized audio** (10 points)"]},{"cell_type":"markdown","metadata":{"id":"2EfQHbJ_r9M7"},"source":["Plot spectrograms for your original utterance and synthesized utterance next to one another. Describe the differences you notice when listening in the audio, and how you think such differences register in the spectrogram plot."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SO8GeUQv5KcW"},"outputs":[],"source":["    #############################\n","    #### YOUR CODE GOES HERE ####\n","\n","    #############################"]},{"cell_type":"markdown","metadata":{"id":"fky4JUBvxFoh"},"source":["# Try variations of input examples\n","\n","Now that we've gotten the hang of it, please use the tool to comment on what you notice from the audio and mel spectrogram for some of these situations (these are just ideas, you may choose what you actually try):\n","\n","1. Speak very monotone and synthesize the exact same words you said. \n","1. Speak very expressively and synthesize the exact same words you said.\n","1. Speak a fixed input and synthesize a phrase with common words, then using the same input synthesize a phrase with rare words. "]},{"cell_type":"markdown","metadata":{"id":"nTQI2zb9uZL8"},"source":["## **Task: Try at least 2 input variations** (10 points)"]},{"cell_type":"markdown","metadata":{"id":"ZPsB6jDevOvc"},"source":["Try two different input audio files and/or input audio / transcription request pairing. See how the voice cloning system responds when you are more expressive, accented, or when synthesizing non-standard words (e.g. technical jargon with TTS pronunciation errors).\n","\n","Run voice conversion on two new examples."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PYc8p8dxvykN"},"outputs":[],"source":["    #############################\n","    #### YOUR CODE GOES HERE ####\n","\n","    #############################"]},{"cell_type":"markdown","metadata":{"id":"8ZDeza2CzTr2"},"source":["## **Task: Comment on what you notice from the mel spectrograms and audio.** (10 points)"]},{"cell_type":"markdown","metadata":{"id":"-vaBqPUmvvBL"},"source":["For the new examples you just generated, comment on your findings about how the voice conversion system responds when you alter inputs used to build the samples (input text or audio samples). \n","\n","Show at least two spectrograms and comment on your findings about how the system works for the types of inputs you tried."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T20343Bmv4cJ"},"outputs":[],"source":["    #############################\n","    #### YOUR CODE GOES HERE ####\n","\n","    #############################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3hGny6giwkKc"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"HW4 Voice Cloning clean.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}